{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Ensure that libraries are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tira>=0.0.141 ir-datasets python-terrier==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -Rf ~/.tira/extracted_datasets/ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test\n",
    "!rm -Rf ~/.tira/.archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTerrier 0.10.0 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# This command loads and starts PyTerrier so that it also works in TIRA.\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "\n",
    "ensure_pyterrier_is_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTerrier must be imported after `ensure_pyterrier_is_loaded` is called.\n",
    "\n",
    "from pyterrier import started, init\n",
    "\n",
    "if not started():\n",
    "    init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRDSDataset('ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier import get_dataset\n",
    "\n",
    "dataset = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the retrieval pipeline with TIRA\n",
    "\n",
    "In this example, we will just use two existing retrieval components from TIREx: BM25 and DirichletLM, two lexical rankers.\n",
    "We load the approaches via the TIRA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.rest_api_client import Client\n",
    "\n",
    "tira_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TiraSourceTransformer()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-th25/BM25 + LLM Data Cleaning',\n",
    "    dataset='subsampled-ms-marco-ir-lab-20250105-test',\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 1.09MiB [00:00, 9.88MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /home/codespace/.tira/extracted_runs/ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training/ir-wise-24-th25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TiraSourceTransformer()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-th25/Baseline Readability Sentence',\n",
    "    dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TiraSourceTransformer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-uk-ir-1/BM25',\n",
    "    dataset='subsampled-ms-marco-ir-lab-20250105-test',\n",
    ")\n",
    "bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 1.11MiB [00:00, 10.1MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /home/codespace/.tira/extracted_runs/ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training/ir-wise-24-th25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TiraSourceTransformer()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = tira_client.pt.from_retriever_submission(\n",
    "    approach='ir-lab-wise-2024/ir-wise-24-th25/Unchanged BM25 Baseline',\n",
    "    dataset='subsampled-ms-marco-deep-learning-20241201-training',\n",
    ")\n",
    "bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Measure effectiveness\n",
    "\n",
    "Now let us measure the nDCG@10 effectiveness of both systems on the Touché 2020 task 1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from Zenodo: https://zenodo.org/records/14743268/files/subsampled-ms-marco-ir-lab-20250105-test-truths.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 50.6k/50.6k [00:00<00:00, 59.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /home/codespace/.tira/extracted_datasets/ir-lab-wise-2024/subsampled-ms-marco-ir-lab-20250105-test/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BM25</td>\n",
       "      <td>45</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>BM25</td>\n",
       "      <td>28</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.463926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BM25</td>\n",
       "      <td>36</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.220092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>BM25</td>\n",
       "      <td>31</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>BM25</td>\n",
       "      <td>4</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>BM25</td>\n",
       "      <td>25</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>BM25</td>\n",
       "      <td>29</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CleaningLLM</td>\n",
       "      <td>14</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.505360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CleaningLLM</td>\n",
       "      <td>4</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.861138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CleaningLLM</td>\n",
       "      <td>19</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.078398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name qid      measure     value\n",
       "57         BM25  45  ndcg_cut_10  1.000000\n",
       "71         BM25  28  ndcg_cut_10  0.463926\n",
       "62         BM25  36  ndcg_cut_10  0.220092\n",
       "87         BM25  31  ndcg_cut_10  0.000000\n",
       "70         BM25   4  ndcg_cut_10  1.000000\n",
       "69         BM25  25  ndcg_cut_10  0.000000\n",
       "79         BM25  29  ndcg_cut_10  1.000000\n",
       "37  CleaningLLM  14  ndcg_cut_10  0.505360\n",
       "24  CleaningLLM   4  ndcg_cut_10  0.861138\n",
       "22  CleaningLLM  19  ndcg_cut_10  0.078398"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.pipelines import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    retr_systems=[\n",
    "        llm,\n",
    "        bm25,\n",
    "    ],\n",
    "    topics=dataset.get_topics(\"query\"),\n",
    "    qrels=dataset.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\"],\n",
    "    names=[\n",
    "        \"CleaningLLM\",\n",
    "        \"BM25\",\n",
    "    ],\n",
    "    perquery=True,\n",
    ")\n",
    "experiment.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>measure</th>\n",
       "      <th>value_bm25</th>\n",
       "      <th>value_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.546257</td>\n",
       "      <td>0.312529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.063621</td>\n",
       "      <td>0.218195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.224663</td>\n",
       "      <td>0.066254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.921602</td>\n",
       "      <td>0.505360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.643404</td>\n",
       "      <td>0.532141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>0.425208</td>\n",
       "      <td>0.078398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>ndcg_cut_10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid      measure  value_bm25  value_llm\n",
       "0  10  ndcg_cut_10    0.546257   0.312529\n",
       "1  11  ndcg_cut_10    0.063621   0.218195\n",
       "2  12  ndcg_cut_10    0.224663   0.066254\n",
       "3  13  ndcg_cut_10    1.000000   0.305235\n",
       "4  14  ndcg_cut_10    0.921602   0.505360\n",
       "5  16  ndcg_cut_10    0.643404   0.532141\n",
       "6  17  ndcg_cut_10    0.000000   0.000000\n",
       "7  18  ndcg_cut_10    0.000000   0.000000\n",
       "8  19  ndcg_cut_10    0.425208   0.078398\n",
       "9   2  ndcg_cut_10    1.000000   1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_bm25 = experiment[experiment[\"name\"] == \"BM25\"]\\\n",
    "    .drop(columns=[\"name\"])\n",
    "experiment_llm = experiment[experiment[\"name\"] == \"CleaningLLM\"]\\\n",
    "    .drop(columns=[\"name\"])\n",
    "\n",
    "experiment_paired = experiment_bm25.merge(\n",
    "    experiment_llm,\n",
    "    on=[\"qid\", \"measure\"],\n",
    "    suffixes=(\"_bm25\", \"_llm\"),\n",
    ")\n",
    "experiment_paired.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Conduct hypothesis tests\n",
    "\n",
    "On this _paired_ measurement data, we can now conduct _paired_ t-tests to test for statistical significance of given hypotheses.\n",
    "Remember that the choice of your test depends (amongst other factors) on how the hypothesis is formulated.\n",
    "\n",
    "Let us test some hypotheses to get a feeling of what this means:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 1: Der Einsatz von Large Language Models (LLMs) für das Data Cleaning zusätzlich zur BM25-Methode führt zu signifikant verbesserten NDCG@10-Werten im Vergleich zur BM25-Methode, da LLMs in der Lage sind, Datenkontexte und semantische Beziehungen besser zu erfassen.\n",
    "\n",
    "Significance test: one-sided paired t-test \\\n",
    "Significance level: $\\alpha = 0.05$ (or $p < 0.05$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.043442907048412e-06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(\n",
    "    experiment_paired[\"value_llm\"],\n",
    "    experiment_paired[\"value_bm25\"],\n",
    "    alternative='two-sided',\n",
    ").pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is lower than the significance level. It suggests there is a statistically significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999954782785465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(\n",
    "    experiment_paired[\"value_llm\"],\n",
    "    experiment_paired[\"value_bm25\"],\n",
    "    alternative='greater',\n",
    ").pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability p of the null hypothesis is higher than our significance level alpha.\n",
    "So we cannot reject the null hypothesis and fail to confirm hypothesis 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
