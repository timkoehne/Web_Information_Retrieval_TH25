{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Lab WiSe 2024/2025: Baseline Retrieval System\n",
    "\n",
    "This Jupyter notebook serves as a baseline retrieval system that you can improve upon.\n",
    "We use subsets of the MS MARCO datasets to retrieve passages of web documents.\n",
    "We will show you how to create a software submission to TIRA from this notebook.\n",
    "\n",
    "An overview of all corpora that we use in the current course is available at [https://tira.io/datasets?query=ir-lab-wise-2024](https://tira.io/datasets?query=ir-lab-wise-2024). The dataset IDs for loading the datasets are:\n",
    "\n",
    "- `ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training`: A subsample of the TREC 2019/2020 Deep Learning tracks on the MS MARCO v1 passage dataset. Use this dataset to tune your system(s).\n",
    "- `ir-lab-wise-2024/subsampled-ms-marco-rag-20241202-training` (_work in progress_): A subsample of the TREC 2024 Retrieval-Augmented Generation track on the MS MARCO v2.1 passage dataset. Use this dataset to tune your system(s).\n",
    "- `ir-lab-wise-2024/ms-marco-rag-20241203-test` (work in progress): The test corpus that we have created together in the course, based on the MS MARCO v2.1 passage dataset. We will use this dataset as the test dataset, i.e., evaluation scores become available only after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "\n",
    "We will use [tira](https://tira.io/), an information retrieval shared task platform, and [ir_dataset](https://ir-datasets.com/) for loading the datasets. Subsequently, we will build a retrieval system with [PyTerrier](https://github.com/terrier-org/pyterrier), an open-source search engine framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira>=0.0.139 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (0.0.139)\n",
      "Requirement already satisfied: ir-datasets in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (0.5.9)\n",
      "Requirement already satisfied: python-terrier==0.10.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (2.2.3)\n",
      "Requirement already satisfied: wget in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.6.1)\n",
      "Requirement already satisfied: matchpy in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.5.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.5.2)\n",
      "Requirement already satisfied: deprecated in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.2.15)\n",
      "Requirement already satisfied: chest in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (2.32.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.4.2)\n",
      "Requirement already satisfied: nptyping==1.4.4 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (1.4.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (10.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (3.1.4)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.14.4)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.3.6)\n",
      "Requirement already satisfied: dill in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.3.9)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-terrier==0.10.0) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from nptyping==1.4.4->python-terrier==0.10.0) (1.9.3)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from tira>=0.0.139) (7.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from tira>=0.0.139) (24.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from docker==7.*,>=7.1.0->tira>=0.0.139) (307)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from docker==7.*,>=7.1.0->tira>=0.0.139) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests->python-terrier==0.10.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests->python-terrier==0.10.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests->python-terrier==0.10.0) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (5.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (6.0.2)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (0.1.9)\n",
      "Requirement already satisfied: ijson>=3.1.3 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (3.3.0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from tqdm->python-terrier==0.10.0) (0.4.6)\n",
      "Requirement already satisfied: cbor>=1.0.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from chest->python-terrier==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from deprecated->python-terrier==0.10.0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from jinja2->python-terrier==0.10.0) (3.0.2)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from matchpy->python-terrier==0.10.0) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pandas->python-terrier==0.10.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pandas->python-terrier==0.10.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pandas->python-terrier==0.10.0) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from scikit-learn->python-terrier==0.10.0) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from statsmodels->python-terrier==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->python-terrier==0.10.0) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"tira>=0.0.139\" ir-datasets \"python-terrier==0.10.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an API client to interact with the TIRA platform (e.g., to load datasets and submit runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the dataset\n",
    "\n",
    "We load the dataset by its ir_datasets ID (as listed in the Readme). Just be sure to add the `irds:` prefix before the dataset ID to tell PyTerrier to load the data from ir_datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\timko\\anaconda3\\envs\\wir\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 10.5 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 9.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.3 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from typing import Iterable\n",
    "import os\n",
    "import data_cleaning\n",
    "reload(data_cleaning)\n",
    "\n",
    "class DataCleaningIter(Iterable):\n",
    "    def __init__(self, dataset_iter, remove_token_tags: list[str]) -> None:\n",
    "        self.dataset_iter = iter(dataset_iter)\n",
    "        self.remove_token_tags = remove_token_tags\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        item = next(self.dataset_iter)\n",
    "        \n",
    "        edited_text = []\n",
    "        doc = nlp(item[\"text\"])\n",
    "        for token in doc:\n",
    "            if token.pos_ in self.remove_token_tags:\n",
    "                # print(f\"removing {token} because it is a {token.pos_}\")\n",
    "                pass\n",
    "            else:\n",
    "                edited_text.append(str(token))\n",
    "        \n",
    "        item[\"text\"] = \" \".join(edited_text)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "spacy_token_tags = ['DET', 'INTJ', 'ADJ', 'VERB', 'PRON', 'CCONJ', 'PART', 'X', 'ADV', 'PUNCT', 'SCONJ', 'SYM', 'SPACE', 'NUM', 'ADP', 'AUX', 'PROPN', 'NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"token_tag\": spacy_token_tags,\n",
    "}\n",
    "param_grid = ParameterGrid(params)\n",
    "\n",
    "results = []\n",
    "names = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [03:36<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data_cleaning_iter = DataCleaningIter(pt_dataset.get_corpus_iter(verbose=True), \"\")\n",
    "\n",
    "index_path = os.getcwd() + os.sep + \"index\"\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    index_path = index_path\n",
    "    index = pt.IndexFactory.of(index_path) \n",
    "else:\n",
    "    indexer = pt.IterDictIndexer(\n",
    "        index_path=index_path,\n",
    "        meta={'docno': 50, 'text': 4096},\n",
    "        # If an index already exists there, then overwrite it.\n",
    "        overwrite=False\n",
    "    )\n",
    "    index = indexer.index(data_cleaning_iter)\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "experiment_results = pt.Experiment([bm25],\n",
    "    pt_dataset.get_topics('text'),\n",
    "    pt_dataset.get_qrels(),\n",
    "    eval_metrics = [\"map\", \"recip_rank\", \"ndcg_cut_10\", \"P_1\", \"P_5\", \"P_10\"]\n",
    ")\n",
    "results.append(experiment_results)\n",
    "names.append(\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:04<01:14,  4.36s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 17%|█▋        | 3/18 [00:12<01:03,  4.23s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 28%|██▊       | 5/18 [00:21<00:54,  4.23s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 39%|███▉      | 7/18 [00:29<00:46,  4.27s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 50%|█████     | 9/18 [00:38<00:38,  4.27s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 61%|██████    | 11/18 [00:46<00:29,  4.22s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 72%|███████▏  | 13/18 [00:55<00:21,  4.21s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 83%|████████▎ | 15/18 [01:03<00:12,  4.23s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      " 94%|█████████▍| 17/18 [01:12<00:04,  4.31s/it]\n",
      "\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:04<?, ?it/s]\n",
      "100%|██████████| 18/18 [01:15<00:00,  4.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, p in tqdm.tqdm(enumerate(param_grid), total=len(spacy_token_tags)):\n",
    "    data_cleaning_iter = DataCleaningIter(\n",
    "        pt_dataset.get_corpus_iter(verbose=True), [p[\"token_tag\"]]\n",
    "    )\n",
    "    index_path = os.getcwd() + os.sep + f\"index-{i}\"\n",
    "\n",
    "    if os.path.exists(index_path):\n",
    "        index_path = index_path\n",
    "        index = pt.IndexFactory.of(index_path)\n",
    "    else:\n",
    "        indexer = pt.IterDictIndexer(\n",
    "            index_path=index_path,\n",
    "            meta={\"docno\": 50, \"text\": 4096},\n",
    "            # If an index already exists there, then overwrite it.\n",
    "            overwrite=False,\n",
    "        )\n",
    "        index = indexer.index(data_cleaning_iter)\n",
    "    bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "    experiment_results = pt.Experiment(\n",
    "        [bm25],\n",
    "        pt_dataset.get_topics(\"text\"),\n",
    "        pt_dataset.get_qrels(),\n",
    "        eval_metrics=[\"map\", \"recip_rank\", \"ndcg_cut_10\", \"P_1\", \"P_5\", \"P_10\"],\n",
    "    )\n",
    "    results.append(experiment_results)\n",
    "    names.append(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_5</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.412570</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.488841</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'token_tag': 'DET'}</td>\n",
       "      <td>0.412687</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.488207</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'token_tag': 'INTJ'}</td>\n",
       "      <td>0.411576</td>\n",
       "      <td>0.785020</td>\n",
       "      <td>0.487932</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'token_tag': 'ADJ'}</td>\n",
       "      <td>0.367286</td>\n",
       "      <td>0.743099</td>\n",
       "      <td>0.441431</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.534021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'token_tag': 'VERB'}</td>\n",
       "      <td>0.382058</td>\n",
       "      <td>0.733259</td>\n",
       "      <td>0.430185</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.569072</td>\n",
       "      <td>0.515464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'token_tag': 'PRON'}</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.788805</td>\n",
       "      <td>0.489165</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'token_tag': 'CCONJ'}</td>\n",
       "      <td>0.412701</td>\n",
       "      <td>0.786939</td>\n",
       "      <td>0.488706</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'token_tag': 'PART'}</td>\n",
       "      <td>0.412541</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.489154</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'token_tag': 'X'}</td>\n",
       "      <td>0.412144</td>\n",
       "      <td>0.785911</td>\n",
       "      <td>0.488158</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.614433</td>\n",
       "      <td>0.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'token_tag': 'ADV'}</td>\n",
       "      <td>0.412123</td>\n",
       "      <td>0.786666</td>\n",
       "      <td>0.487221</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.572165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'token_tag': 'PUNCT'}</td>\n",
       "      <td>0.411951</td>\n",
       "      <td>0.785650</td>\n",
       "      <td>0.487653</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'token_tag': 'SCONJ'}</td>\n",
       "      <td>0.412617</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.488955</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'token_tag': 'SYM'}</td>\n",
       "      <td>0.412143</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.488873</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'token_tag': 'SPACE'}</td>\n",
       "      <td>0.412570</td>\n",
       "      <td>0.786510</td>\n",
       "      <td>0.488841</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.574227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'token_tag': 'NUM'}</td>\n",
       "      <td>0.414252</td>\n",
       "      <td>0.779606</td>\n",
       "      <td>0.487836</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.616495</td>\n",
       "      <td>0.577320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'token_tag': 'ADP'}</td>\n",
       "      <td>0.412707</td>\n",
       "      <td>0.786507</td>\n",
       "      <td>0.488505</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.620619</td>\n",
       "      <td>0.575258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'token_tag': 'AUX'}</td>\n",
       "      <td>0.412462</td>\n",
       "      <td>0.791188</td>\n",
       "      <td>0.490190</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>0.616495</td>\n",
       "      <td>0.572165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'token_tag': 'PROPN'}</td>\n",
       "      <td>0.272392</td>\n",
       "      <td>0.663012</td>\n",
       "      <td>0.358661</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.501031</td>\n",
       "      <td>0.437113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'token_tag': 'NOUN'}</td>\n",
       "      <td>0.243468</td>\n",
       "      <td>0.643414</td>\n",
       "      <td>0.324745</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.441237</td>\n",
       "      <td>0.405155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name       map  recip_rank  ndcg_cut_10       P_1  \\\n",
       "0                     BM25  0.412570    0.786510     0.488841  0.701031   \n",
       "1     {'token_tag': 'DET'}  0.412687    0.786510     0.488207  0.701031   \n",
       "2    {'token_tag': 'INTJ'}  0.411576    0.785020     0.487932  0.701031   \n",
       "3     {'token_tag': 'ADJ'}  0.367286    0.743099     0.441431  0.639175   \n",
       "4    {'token_tag': 'VERB'}  0.382058    0.733259     0.430185  0.628866   \n",
       "5    {'token_tag': 'PRON'}  0.414859    0.788805     0.489165  0.701031   \n",
       "6   {'token_tag': 'CCONJ'}  0.412701    0.786939     0.488706  0.701031   \n",
       "7    {'token_tag': 'PART'}  0.412541    0.786510     0.489154  0.701031   \n",
       "8       {'token_tag': 'X'}  0.412144    0.785911     0.488158  0.701031   \n",
       "9     {'token_tag': 'ADV'}  0.412123    0.786666     0.487221  0.701031   \n",
       "10  {'token_tag': 'PUNCT'}  0.411951    0.785650     0.487653  0.701031   \n",
       "11  {'token_tag': 'SCONJ'}  0.412617    0.786510     0.488955  0.701031   \n",
       "12    {'token_tag': 'SYM'}  0.412143    0.786510     0.488873  0.701031   \n",
       "13  {'token_tag': 'SPACE'}  0.412570    0.786510     0.488841  0.701031   \n",
       "14    {'token_tag': 'NUM'}  0.414252    0.779606     0.487836  0.690722   \n",
       "15    {'token_tag': 'ADP'}  0.412707    0.786507     0.488505  0.701031   \n",
       "16    {'token_tag': 'AUX'}  0.412462    0.791188     0.490190  0.711340   \n",
       "17  {'token_tag': 'PROPN'}  0.272392    0.663012     0.358661  0.587629   \n",
       "18   {'token_tag': 'NOUN'}  0.243468    0.643414     0.324745  0.515464   \n",
       "\n",
       "         P_5      P_10  \n",
       "0   0.620619  0.574227  \n",
       "1   0.620619  0.573196  \n",
       "2   0.618557  0.573196  \n",
       "3   0.587629  0.534021  \n",
       "4   0.569072  0.515464  \n",
       "5   0.620619  0.574227  \n",
       "6   0.620619  0.574227  \n",
       "7   0.620619  0.574227  \n",
       "8   0.614433  0.573196  \n",
       "9   0.620619  0.572165  \n",
       "10  0.620619  0.573196  \n",
       "11  0.620619  0.574227  \n",
       "12  0.620619  0.574227  \n",
       "13  0.620619  0.574227  \n",
       "14  0.616495  0.577320  \n",
       "15  0.620619  0.575258  \n",
       "16  0.616495  0.572165  \n",
       "17  0.501031  0.437113  \n",
       "18  0.441237  0.405155  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.concat(results, keys=names)\n",
    "all_results = all_results.reset_index().drop([\"name\", \"level_1\"], axis=1).rename(columns={\"level_0\": \"name\"})\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      name       map  recip_rank  ndcg_cut_10       P_1  \\\n",
      "5    {'token_tag': 'PRON'}  0.414859    0.788805     0.489165  0.701031   \n",
      "6   {'token_tag': 'CCONJ'}  0.412701    0.786939     0.488706  0.701031   \n",
      "7    {'token_tag': 'PART'}  0.412541    0.786510     0.489154  0.701031   \n",
      "11  {'token_tag': 'SCONJ'}  0.412617    0.786510     0.488955  0.701031   \n",
      "16    {'token_tag': 'AUX'}  0.412462    0.791188     0.490190  0.711340   \n",
      "\n",
      "         P_5      P_10       avg  \n",
      "5   0.620619  0.574227  0.602896  \n",
      "6   0.620619  0.574227  0.601999  \n",
      "7   0.620619  0.574227  0.601971  \n",
      "11  0.620619  0.574227  0.601946  \n",
      "16  0.616495  0.572165  0.604335  \n",
      "removing these token_tags improves the results: ['PRON', 'CCONJ', 'PART', 'SCONJ', 'AUX']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "all_results[\"avg\"] = all_results.iloc[:, 1:-1].mean(axis=1)\n",
    "\n",
    "bm25_avg = all_results.loc[all_results[\"name\"] == \"BM25\", \"avg\"].values[0]\n",
    "only_better_results = all_results[all_results[\"avg\"] > bm25_avg]\n",
    "print(only_better_results)\n",
    "only_better_token_tags = list(only_better_results[\"name\"].apply(lambda x: json.loads(str(x).replace(\"'\", \"\\\"\"))[\"token_tag\"]))\n",
    "print(f\"removing these token_tags improves the results: {only_better_token_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are:\n",
    "- PRON: Pronoun (e.g., \"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"this\", \"that\")\n",
    "- CCONJ: Coordinating conjunction (e.g., \"and\", \"or\", \"but\")\n",
    "- PART: Particle (e.g., \"not\", \"'s\" in \"cat's\")\n",
    "- SCONJ: Subordinating conjunction (e.g., \"because\", \"although\", \"if\", \"since\")\n",
    "- ADP: Adposition (preposition or postposition) (e.g., \"in\", \"on\", \"at\", \"to\", \"from\")\n",
    "- AUX: Auxiliary verb (e.g., \"is\", \"are\", \"was\", \"were\", \"have\", \"has\", \"had\", \"will\", \"would\", \"can\", \"could\", \"should\", \"may\", \"might\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:   0%|          | 0/68261 [00:26<?, ?it/s]\n",
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 26013/68261 [04:23<07:23, 95.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:39:01.776 [main] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [11:17<00:00, 100.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:45:57.547 [main] WARN org.terrier.structures.indexing.Indexer - Indexed 1 empty documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_5</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.414901</td>\n",
       "      <td>0.793504</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.71134</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.572165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name       map  recip_rank  ndcg_cut_10      P_1       P_5      P_10\n",
       "0  BR(BM25)  0.414901    0.793504     0.491667  0.71134  0.618557  0.572165"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning_iter = DataCleaningIter(pt_dataset.get_corpus_iter(verbose=True), only_better_token_tags)\n",
    "index_path = os.getcwd() + os.sep + f\"index-combined\"\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    index_path = index_path\n",
    "    index = pt.IndexFactory.of(index_path)\n",
    "else:\n",
    "    indexer = pt.IterDictIndexer(\n",
    "    index_path=index_path,\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=False\n",
    ")\n",
    "index = indexer.index(data_cleaning_iter)\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "\n",
    "experiment_results = pt.Experiment([bm25],\n",
    "    pt_dataset.get_topics('text'),\n",
    "    pt_dataset.get_qrels(),\n",
    "    eval_metrics = [\"map\", \"recip_rank\", \"ndcg_cut_10\", \"P_1\", \"P_5\", \"P_10\"],\n",
    "    names=[\"BM25 removed token_types with spacy\"]\n",
    ")\n",
    "\n",
    "experiment_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
